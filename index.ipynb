{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This project examines the Northwind Sample database provided by Microsoft used for training purpose. We need ask 4 questions that require hypothesis testing to answer. Below is a diagram of database\n",
    "\n",
    "\n",
    "**Image using img tag**\n",
    "<!---you can put in images using an img tag--->\n",
    "<img src=\"Northwind_ERD_updated.png\" width=80%>\n",
    "\n",
    "I am asking the following questions\n",
    "\n",
    "### [**Q1**: Does discount amount effect quantity sold?\n",
    "\n",
    "    - Test Used\n",
    "        - TUKEY Test\n",
    "    - Findings\n",
    "            There are statistical difference in the means of the discounted order quantity versus non discounted orders. Also there was not a significant difference among the different levels of discounted orders. These results indicate that having a discount has an effect on the quantity of the purchase, but the level of the discount does not seem to have effect after discount is applied.\n",
    "    \n",
    "### **Q2**: Does a customer's overall discount rate effect their total purchase amount?\n",
    "    - Test Used\n",
    "            - Independent Welch's TTest\n",
    "            - ANOVA\n",
    "            - TUKEY Test\n",
    "    - Findings\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "## Question1\n",
    "<details> <summary> Q1 Information</summary>\n",
    "\n",
    "### Does discount amount have a statistically significant effect on the quantity of a product in an order? If so, at what level(s) of discount?\n",
    "\n",
    "**Gathering my data**\n",
    "\n",
    "```\n",
    "df = get_table(table='OrderDetail')\n",
    "df.head()\n",
    "```\n",
    "![](q1-df-head-01.png)\n",
    "\n",
    "\n",
    "**Split up data if it had a discount or not**\n",
    "```\n",
    "discounted_vals = df.loc[df['has_discount']>0, 'Quantity']\n",
    "non_discounted_vals = df.loc[df['has_discount']==0, 'Quantity']\n",
    "```\n",
    "\n",
    "**Compare Distributions and test for normality**\n",
    "![](question1_files/question1_11_0.png)\n",
    "\n",
    "```\n",
    "test_normality(discounted_vals)\n",
    "p = 6.88120409395894e-26\n",
    "Therefore the data is not normal\n",
    "\n",
    "test_normality(non_discounted_vals)\n",
    "p = 3.803856556577728e-34\n",
    "Therefore the data is not normal\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details><summary>Q1 Strategy</summary>\n",
    "\n",
    "Given that this data is not normal, I needed to take sampling distributions. Doing this resulted in this distribution.\n",
    "\n",
    "![](question1_files/question1_22_0.png)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details open><summary>Q1 Results/Conclusion</summary>\n",
    "\n",
    "### Results\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "### Further Work\n",
    "</details>\n",
    "\n",
    "[Back to Introduction](#Introduction)\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This project examines the Northwind Sample database provided by Microsoft used for training purpose. We need ask 4 questions that require hypothesis testing to answer. Below is a diagram of database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---you can put in images using an img tag--->\n",
    "<img src=\"Northwind_ERD_updated.png\" width=80%>\n",
    "\n",
    "I am asking the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-**Does discount amount have a statistically significant effect on the quantity of a product in an order? If so, at what level(s) of discount?** \n",
    "    <a href='question1.ipynb'>Question 1</a>\n",
    "    \n",
    "-**Does a customer's overall discount rate effect their total purchase amount?**\n",
    "    <a hef='Question2.ipynb'>Question 2</a>\n",
    "\n",
    "-**Does the Northwind Customer database conform to the 80/20 rule? 80% of your sales is accounted for by 20% of your customers.**\n",
    "    <a href='question3.ipynb'>Question 3</a>\n",
    "\n",
    "-**Are discontinued items have a difference discount rate compared to the rest of the items?**\n",
    "    <a href='question4.ipynb'>Question 4</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Does discount amount have a statistically significant effect on the quantity of a product in an order? If so, at what level(s) of discount?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Initial Procedure</summary>\n",
    "    \n",
    "**Gathering my data**\n",
    "\n",
    "I used the below SQL command to gather data from the Order and OrderDetail. Also the total item amount and standard undiscounted line amount were calulated.\n",
    "\n",
    "```\n",
    "query = \"\"\"\n",
    "            SELECT o.ID, ProductID, Quantity, Discount, UnitPrice\n",
    "            FROM 'Order' as o\n",
    "            JOIN 'OrderDetail' as od\n",
    "            on o.ID = od.OrderID\"\"\"\n",
    "\n",
    "df = sql_to_dataframe(query)\n",
    "df.head()\n",
    "# Adding the standard price\n",
    "df['StandardPrice']= df.UnitPrice/(1- df.Discount)\n",
    "# Line total\n",
    "df['LineTotal'] = df.UnitPrice* df.Quantity\n",
    "# Discounted Amount\n",
    "df['StandardAmount'] = df.StandardPrice* df.Quantity\n",
    "```\n",
    "Then I grouped the data by order.\n",
    "```\n",
    "columns = ['Quantity', 'LineTotal', 'StandardAmount', 'Discount']\n",
    "Orders = df.loc[df.Discount == 0].groupby('Id')[columns].sum()\n",
    "````\n",
    "\n",
    "**Split up data if it had a discount or not**\n",
    "```\n",
    "columns = ['Quantity', 'LineTotal', 'StandardAmount', 'Discount']\n",
    "orders_with_no_discount = df.loc[df.Discount == 0].groupby('Id')[columns].sum()\n",
    "orders_with_discount = df.loc[df.Discount != 0].groupby('Id')[columns].sum()\n",
    "```\n",
    "![](question1_files/question1_10_0.png)\n",
    "\n",
    "**Split further into different levels of discount rates**\n",
    "\n",
    "I calulated the discounted rate for each order and then binned discount rates into different levels.\n",
    "```\n",
    "orders_with_discount.Discount = (orders_with_discount.StandardAmount- orders_with_discount.LineTotal)/ orders_with_discount.StandardAmount \n",
    "df_orders = orders_with_discount.append(orders_with_no_discount)\n",
    "hist, bin_edge = np.histogram(df_orders.Discount, bins= 3)\n",
    "#bin_edge[1]=.0725\n",
    "df_orders['BinnedDiscount'] = pd.cut(df_orders['Discount'], bin_edge)\n",
    "df_orders.BinnedDiscount = df_orders.BinnedDiscount.astype(str)\n",
    "df_orders.BinnedDiscount.loc[df_orders.BinnedDiscount == 'nan']= 'No Discount'\n",
    "df_orders = df_orders.sort_values('Discount')\n",
    "```\n",
    "![](question1_files/question1_14_0.png)\n",
    "\n",
    "**Compare Distributions and test for normality**\n",
    "\n",
    "```\n",
    "No Discount\n",
    "non normal\n",
    "t 0.7845940589904785, p 1.1666289823246571e-27\n",
    "(0.0833, 0.167]\n",
    "non normal\n",
    "t 0.8421576023101807, p 2.0802779637785207e-11\n",
    "(0.167, 0.25]\n",
    "non normal\n",
    "t 0.8608901500701904, p 2.496944873087159e-10\n",
    "(0.0, 0.0833]\n",
    "non normal\n",
    "t 0.8759969472885132, p 6.426521395042073e-07\n",
    "```\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "The p values for the order data is below 0.05, so they are not normal. We will use bootstrapping take a sampling distribution of the means.\n",
    "</details>\n",
    "\n",
    "<details><summary>Mean Sampling(Bootstrapping)</summary>\n",
    "Mean samples were taken of all binned values. The number of sample in each binned value category was the same number of the actual sample. See below sample distributions.\n",
    "\n",
    "![](question1_files/question1_23_0.png)\n",
    "\n",
    "**Compare Distribution and test for normality**\n",
    "\n",
    "```\n",
    "No Discount\n",
    "normal\n",
    "t 0.9924347400665283, p 0.9050273895263672\n",
    "(0.0833, 0.167]\n",
    "normal\n",
    "t 0.9831403493881226, p 0.3255539536476135\n",
    "(0.167, 0.25]\n",
    "normal\n",
    "t 0.982770562171936, p 0.3085521161556244\n",
    "(0.0, 0.0833]\n",
    "normal\n",
    "t 0.986225962638855, p 0.4969947636127472\n",
    "```\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "The p values for the mean sampled categor , so they a. We will use bootstrapping take a sampling distribution of the means.\n",
    "\n",
    "**Check for Normality**\n",
    "```\n",
    "No Discount compared to No Discount\n",
    "p = 1.0\n",
    "Therefore the data have equal variances\n",
    "True\n",
    "No Discount compared to (0.0833, 0.167]\n",
    "p = 3.502923887293742e-06\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "No Discount compared to (0.167, 0.25]\n",
    "p = 5.99797771714921e-07\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "No Discount compared to (0.0, 0.0833]\n",
    "p = 1.321440131263909e-08\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "```\n",
    "The null hypothesis is the variances of the two compared distribution are equal. The alternative hypothesis is the variances are not equal.\n",
    "\n",
    "The discounted sample means do not have equal variances with the other discount distribution.\n",
    "\n",
    "**Effect Size**\n",
    "```\n",
    "No Discount compared to No Discount\n",
    "0.0\n",
    "No Discount compared to (0.0833, 0.167]\n",
    "3.7601515099983023\n",
    "No Discount compared to (0.167, 0.25]\n",
    "4.309178544354231\n",
    "No Discount compared to (0.0, 0.0833]\n",
    "3.108343242404973\n",
    "```\n",
    "There is a fairly large effect size for No Discount versus no discount. This result add credence to the eventual final  test.\n",
    "\n",
    "**Tukey Test**\n",
    "\n",
    "![](Capture.png)\n",
    "\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "<details open><summary>Results/Conclusion</summary>\n",
    "There are statistical difference in the means of the discounted order quantity versus non discounted orders. Also there was not a significant difference among the different levels of discounted orders. These results indicate that having a discount has an effect on the quantity of the purchase, but the level of the discount does not seem to have effect after discount is applied. There is a 13.1 quantity increase in the quantity with a discount.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Does a customer's overall discount rate effect their total purchase amount? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Initial Procedure</summary>\n",
    "\n",
    "**Gathering data**\n",
    "    \n",
    "I used the below SQL command to gather data from the Order and OrderDetail. Also the total item amount and standard undiscounted line amount were calulated like the previous. \n",
    "\n",
    "```\n",
    "query =  \"\"\"\n",
    "            SELECT o.ID, CustomerID, ProductID, Quantity, Discount, UnitPrice\n",
    "            FROM 'Order' as o\n",
    "            JOIN 'OrderDetail' as od\n",
    "            on o.ID = od.OrderID \n",
    "        \"\"\"\n",
    "```\n",
    "```\n",
    "# Adding the standard price\n",
    "df['StandardPrice']= df.UnitPrice/(1- df.Discount)\n",
    "# Line total\n",
    "df['LineTotal'] = df.UnitPrice* df.Quantity\n",
    "# Discounted Amount\n",
    "df['StandardAmount'] = df.StandardPrice* df.Quantity\n",
    "```\n",
    "\n",
    "**Creating Customer Specific Data**\n",
    "\n",
    "We grouped the data CustomerID summing the other columns. Using the resulting, we calulated the overall discounted rate for the customer.\n",
    "\n",
    "```\n",
    "columns = ['Quantity', 'LineTotal', 'StandardAmount', 'Discount']\n",
    "df_customer = df.groupby('CustomerId')[columns].sum()\n",
    "df_customer.Discount = (df_customer.StandardAmount- df_customer.LineTotal)/ df_customer.StandardAmount\n",
    "df_customer = df_customer.rename(columns= {'LineTotal':'TotalSpent'})\n",
    "```\n",
    "![](Capture3.png)\n",
    "\n",
    "**Spliting Customer by Discount**\n",
    "\n",
    "As can be seen in the scatterplot below, there is a distinct difference between the discounted and undiscounted customer.  \n",
    "\n",
    "![](Question2_files/Question2_9_0.png)\n",
    "\n",
    "We did a correlation test on discount rate for the customer that recieved discounts, and did not see a signficant relation. Therefore we choose not to explore further.\n",
    "\n",
    "![](Capture2.png)\n",
    "\n",
    "**Compare Distributions**\n",
    "\n",
    "Looking at the distributions, there is quite a lot of overlap. Type 1 and Type 2 could be a substanial problem.\n",
    "\n",
    "![](Question2_files/Question2_13_1.png)\n",
    "\n",
    "**Checking for Normality**\n",
    "```\n",
    "(0.0, 0.211]\n",
    "non normal\n",
    "t 0.6238155364990234, p 1.635892254991944e-10\n",
    "NoDiscount\n",
    "non normal\n",
    "t 0.8218997716903687, p 5.651193714584224e-05\n",
    "```\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05. \n",
    "\n",
    "The p values for the bootstrap order data are below 0.05, so they are non normal. Bootstrapping will need to be used\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Mean Sampling(Bootstrapping)</summary>\n",
    "Mean samples were taken of all two distribution. The number of sample in each category was the same number of the actual sample. See below sample distributions in the violin plot.\n",
    "    \n",
    "![](Question2_files/Question2_21_0.png)\n",
    "\n",
    "**Check for Normality**\n",
    "\n",
    "```\n",
    "(0.0, 0.211]\n",
    "non normal\n",
    "t 0.9280422925949097, p 0.024476362392306328\n",
    "NoDiscount\n",
    "normal\n",
    "t 0.9866995811462402, p 0.9400492906570435\n",
    "```\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "Null hypothesis was not rejected. The p-values are above the threshold, so the distrbutions are normal.\n",
    "\n",
    "**Equal Variance Test**\n",
    "\n",
    "```\n",
    "p = 4.106068830965434e-07\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "```\n",
    "The sample distributions don't have equal variances.\n",
    "\n",
    "**Effect Size**\n",
    "```\n",
    "No Discount compared to Discounted\n",
    "6.736325547832778\n",
    "```\n",
    "The effect size is signficant.\n",
    "\n",
    "**Welch's T Test**\n",
    "\n",
    "```\n",
    "scs.ttest_ind(df_mean_sampling.loc[df_mean_sampling.BinnedValue == 'NoDiscount'].TotalSpent,\n",
    "                      df_mean_sampling.loc[df_mean_sampling.BinnedValue == '(0.0, 0.211]'].TotalSpent, equal_var=False)\n",
    "Ttest_indResult(statistic=-28.180071557959714, pvalue=1.7148430384448146e-25)\n",
    "```\n",
    " Rejected the null hypothesis(the sample means are identical)                \n",
    "\n",
    "</details>\n",
    "\n",
    "<details open><summary>Results/Conclusion</summary>\n",
    "\n",
    "There is statistical significant difference in total dollars spent with customers that received discount and those that did not. There is a $19,886.88 positive increase the average of the non discounted customer to the discounted customers Among the discounted customer, there did not seem to be a significant relationship between the spent and the level of discounts.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Does the Northwind Customer database conform to the 80/20 rule, 80% of your sales is accounted for by 20% of your customers.\n",
    "\n",
    "We will answer this question by first determining if there is a statistically significant difference in the mean revenue of the top 20 percentile of customers by total revenue and that of all the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Initial Procedure</summary>\n",
    "\n",
    "**Gathering data**\n",
    "    \n",
    "I used the below SQL command to gather data from the Order and OrderDetail. Also the total item amount were calulated.\n",
    "\n",
    "```\n",
    "query =  \"\"\"\n",
    "            SELECT o.ID, CustomerID, ProductID, Quantity, Discount, UnitPrice\n",
    "            FROM 'Order' as o\n",
    "            JOIN 'OrderDetail' as od\n",
    "            on o.ID = od.OrderID \n",
    "        \"\"\"\n",
    "```\n",
    "```\n",
    "df = conn.load_query_as_df(query)\n",
    "# Line total\n",
    "df['LineTotal'] = df.UnitPrice* df.Quantity\n",
    "```\n",
    "Then the data is grouped by CustomerID and the sums of Quantity and LineTotal.\n",
    "```\n",
    "columns = ['Quantity', 'LineTotal']\n",
    "df_customer = df.groupby('CustomerId')[columns].sum()\n",
    "df_customer = df_customer.rename(columns= {'LineTotal':'Revenue'})\n",
    "```\n",
    "![](Capture3.png)\n",
    "\n",
    "\n",
    "**Split the Top 20 Away from the Rest of the Customer**\n",
    "```\n",
    "df_customer['Top20']= df_customer.Revenue >=df_customer.Revenue.quantile(.8)\n",
    "```\n",
    "![](question3_files/question3_11_0.png)\n",
    "\n",
    "\n",
    "**Check for Normality**\n",
    "```\n",
    "Total\n",
    "normal\n",
    "t 0.9926739931106567, p 0.9068521857261658\n",
    "Bottom 80%\n",
    "normal\n",
    "t 0.9807733297348022, p 0.34766462445259094\n",
    "Top 20%\n",
    "normal\n",
    "t 0.9199103116989136, p 0.12880030274391174\n",
    "```\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "*Null hypothesis was not rejected for all samples.* The p-values are below the threshold, so the distrbutions are normal. \n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Mean Sampling(Bootstrapping)</summary>\n",
    "    \n",
    "Mean samples of all the revenue . The number of sample in each binned value category was the same number of the actual sample. See below sample distributions.\n",
    "\n",
    "![](question3_files/question3_16_0.png)\n",
    "\n",
    "**Check for Normality**\n",
    "```\n",
    "Total\n",
    "normal\n",
    "t 0.9845062494277954, p 0.37095606327056885\n",
    "Bottom 80%\n",
    "normal\n",
    "t 0.9890205264091492, p 0.7960888743400574\n",
    "Top 20%\n",
    "normal\n",
    "t 0.966257631778717, p 0.7251107096672058\n",
    "```\n",
    "\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "Null hypothesis was not rejected for all samples. The p-values are below the threshold, so the distrbutions are normal.\n",
    "\n",
    "**Equal Variance Test**\n",
    "\n",
    "```\n",
    "p = 1.0392084009178214e-11\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "```\n",
    "The sample distributions don't have equal variances.\n",
    "\n",
    "**Effect Size**\n",
    "```\n",
    "7.401363764370244\n",
    "```\n",
    "The effect size is signficant.\n",
    "\n",
    "**Welch's T Test**\n",
    "\n",
    "```\n",
    "Top20 compared to Total\n",
    "Ttest_indResult(statistic=-14.950287169424096, pvalue=1.9845001084903893e-11)\n",
    "```\n",
    " Rejected the null hypothesis(the sample means are identical)                \n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "<details open><summary>Results/Conclusion</summary>\n",
    "\n",
    "\n",
    "There a statistically significant difference in the mean revenue of the top 20 percentile of customers by total revenue and that of all the customers. There is a $30,480.70 positive increase the average revenue of the whole customer base to the average revenue among the top 20% of customers. Although only 60.73% of the revenues come from the top 20%\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Are discontinued items have a difference discount rate compared to the rest of the items?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Initial Procedure</summary>\n",
    "\n",
    "**Gathering data**\n",
    "    \n",
    "I used the below SQL command to gather data from the Order, Product, and OrderDetail. Also we created total revenue and month columns. \n",
    "\n",
    "```\n",
    "query =  \"\"\"\n",
    "            SELECT o.OrderDate, od.UnitPrice, od.Quantity, p.Discontinued, od.Discount\n",
    "            from OrderDetail as od\n",
    "            join 'Order' as o\n",
    "            on o.Id = od.OrderId\n",
    "            join Product as p\n",
    "            on p.Id = od.ProductId\n",
    "        \"\"\"\n",
    "```\n",
    "```\n",
    "df = conn.load_query_as_df(query)\n",
    "df['Total'] = df.Quantity* df.UnitPrice\n",
    "df['DateTimeOrder'] = pd.to_datetime(df.OrderDate)\n",
    "df['YrMonth'] = df.OrderDate.apply(lambda x: x[:7])\n",
    "df['Count'] = df.OrderDate.apply(lambda x:1)\n",
    "```\n",
    "![](question4_files/question4_10_0.png)\n",
    "```\n",
    "\n",
    "```\n",
    "Grouping the data by month, you can see the difference in three distributions.\n",
    "\n",
    "\n",
    "![](question4_files/question4_7_0.png)\n",
    "![](question4_files/question4_8_0.png)\n",
    "![](question4_files/question4_9_0.png)\n",
    "\n",
    "**Check in Normality**\n",
    "```\n",
    "All\n",
    "non normal\n",
    "t 0.6950738430023193, p 0.0\n",
    "Discontinued\n",
    "non normal\n",
    "t 0.6778910160064697, p 1.3102864828060304e-20\n",
    "Normal\n",
    "non normal\n",
    "t 0.6968779563903809, p 0.0\n",
    "```\n",
    "\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "Reject the null hypothesis. All 3 distrbutions are non normal. Will use bootstrapping and will examine sample means.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Mean Sampling(Bootstrapping)</summary>\n",
    "\n",
    "Mean samples of discount rate are take for all order lines, discontinued products and the normal products. The number of sample in each distribution was the same number of the actual size of the distritbution. See below sample distributions.\n",
    "![](question4_files/question4_18_1.png)\n",
    "\n",
    "```\n",
    "all_sample_mean = func.bootstrapping(df.Discount, num_of_samples=1000)\n",
    "\n",
    "discontinued_sample_mean = func.bootstrapping(df.loc[df.Discontinued == 1].Discount, \n",
    "                                          num_of_samples=1000)\n",
    "\n",
    "normal_sample_mean = func.bootstrapping(df.loc[df.Discontinued == 0].Discount,\n",
    "                                        num_of_samples=1000)\n",
    "```\n",
    "**Check for Normality**\n",
    "\n",
    "```All\n",
    "non normal\n",
    "t 0.9964560270309448, p 0.023196538910269737\n",
    "Discontinued\n",
    "normal\n",
    "t 0.9987639784812927, p 0.7313024997711182\n",
    "Normal\n",
    "normal\n",
    "t 0.998462438583374, p 0.5303573608398438\n",
    "```\n",
    "\n",
    "The null hypothesis is that the tested distribution is normally distributed, and the alternative hypothesis is that the distribution is non-normal. A p values threshold is 0.05.\n",
    "\n",
    "The null failed to be rejected. The distrubtion can be considered normal.\n",
    "\n",
    "**Variance Test**\n",
    "\n",
    "```\n",
    "func.levene_variances(all_sample_mean, normal_sample_mean)\n",
    "p = 0.04816569617190274\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "```\n",
    "\n",
    "```\n",
    "func.levene_variances(all_sample_mean, discontinued_sample_mean)\n",
    "p = 1.2284988167112896e-134\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "```\n",
    "```\n",
    "func.levene_variances(discontinued_sample_mean, normal_sample_mean)\n",
    "p = 3.854038813759604e-127\n",
    "Therefore the data do not have equal variances\n",
    "False\n",
    "```\n",
    "The discontinued samples had difference variance compared to the other distributions.\n",
    "\n",
    "**Effect Size**\n",
    "\n",
    "```\n",
    "func.cohen_d(all_sample_mean, normal_sample_mean)\n",
    "-0.1523233592759832\n",
    "```\n",
    "```\n",
    "func.cohen_d(all_sample_mean, discontinued_sample_mean)\n",
    "0.1826323674984884\n",
    "```\n",
    "```\n",
    "func.cohen_d(discontinued_sample_mean, normal_sample_mean)\n",
    "-0.2499484603113419\n",
    "```\n",
    "\n",
    "The effect size are not very big, and would cause question a reject of the null hypothesis in a Welch's T test\n",
    "\n",
    "**Welch T Test**\n",
    "\n",
    "```\n",
    "scs.ttest_ind(discontinued_sample_mean, normal_sample_mean, equal_var=False)\n",
    "Ttest_indResult(statistic=-5.589017481275687, pvalue=2.8111357710968543e-08)\n",
    "\n",
    "scs.ttest_ind(all_sample_mean, discontinued_sample_mean, equal_var=False)\n",
    "Ttest_indResult(statistic=4.083783886183433, pvalue=4.7219796460801225e-05)\n",
    "```\n",
    "\n",
    "Failed to reject the null hypothesis(the sample means are identical)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details open><summary>Results/Conclusion</summary>\n",
    "\n",
    "There is not statistical signficant difference in between discount rate of the discontinued items versus either\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application is used to convert notebook files (*.ipynb) to various other\n",
      "formats.\n",
      "\n",
      "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "\n",
      "-------\n",
      "\n",
      "\n",
      "\n",
      "Arguments that take values are actually convenience aliases to full\n",
      "Configurables, whose aliases are listed on the help line. For more information\n",
      "on full configurables, see '--help-all'.\n",
      "\n",
      "\n",
      "--debug\n",
      "\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "\n",
      "--generate-config\n",
      "\n",
      "    generate default config file\n",
      "\n",
      "-y\n",
      "\n",
      "    Answer yes to any questions instead of prompting.\n",
      "\n",
      "--execute\n",
      "\n",
      "    Execute the notebook prior to export.\n",
      "\n",
      "--allow-errors\n",
      "\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "\n",
      "--stdin\n",
      "\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "\n",
      "--stdout\n",
      "\n",
      "    Write notebook output to stdout instead of files.\n",
      "\n",
      "--inplace\n",
      "\n",
      "    Run nbconvert in place, overwriting the existing notebook (only \n",
      "    relevant when converting to notebook format)\n",
      "\n",
      "--clear-output\n",
      "\n",
      "    Clear output of current file and save in place, \n",
      "    overwriting the existing notebook.\n",
      "\n",
      "--no-prompt\n",
      "\n",
      "    Exclude input and output prompts from converted document.\n",
      "\n",
      "--no-input\n",
      "\n",
      "    Exclude input cells and output prompts from converted document. \n",
      "    This mode is ideal for generating code-free reports.\n",
      "--log-level=<Enum> (Application.log_level)\n",
      "\n",
      "    Default: 30\n",
      "\n",
      "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
      "\n",
      "    Set the log level by value or name.\n",
      "\n",
      "--config=<Unicode> (JupyterApp.config_file)\n",
      "\n",
      "    Default: ''\n",
      "\n",
      "    Full path of a config file.\n",
      "\n",
      "--to=<Unicode> (NbConvertApp.export_format)\n",
      "\n",
      "    Default: 'html'\n",
      "\n",
      "    The export format to be used, either one of the built-in formats\n",
      "\n",
      "    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\n",
      "\n",
      "    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\n",
      "\n",
      "    the import path for an `Exporter` class\n",
      "\n",
      "--template=<Unicode> (TemplateExporter.template_file)\n",
      "\n",
      "    Default: ''\n",
      "\n",
      "    Name of the template file to use\n",
      "\n",
      "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
      "\n",
      "    Default: 'FilesWriter'\n",
      "\n",
      "    Writer class used to write the  results of the conversion\n",
      "\n",
      "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
      "\n",
      "    Default: ''\n",
      "\n",
      "    PostProcessor class used to write the results of the conversion\n",
      "\n",
      "--output=<Unicode> (NbConvertApp.output_base)\n",
      "\n",
      "    Default: ''\n",
      "\n",
      "    overwrite base name use for output files. can only be used when converting\n",
      "\n",
      "    one notebook at a time.\n",
      "\n",
      "--output-dir=<Unicode> (FilesWriter.build_directory)\n",
      "\n",
      "    Default: ''\n",
      "\n",
      "    Directory to write output(s) to. Defaults to output to the directory of each\n",
      "\n",
      "    notebook. To recover previous default behaviour (outputting to the current\n",
      "\n",
      "    working directory) use . as the flag value.\n",
      "\n",
      "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n",
      "\n",
      "    Default: ''\n",
      "\n",
      "    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,\n",
      "\n",
      "    but can be any url pointing to a copy  of reveal.js.\n",
      "\n",
      "    For speaker notes to work, this must be a relative path to a local  copy of\n",
      "\n",
      "    reveal.js: e.g., \"reveal.js\".\n",
      "\n",
      "    If a relative path is given, it must be a subdirectory of the current\n",
      "\n",
      "    directory (from which the server is run).\n",
      "\n",
      "    See the usage documentation\n",
      "\n",
      "    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-\n",
      "\n",
      "    slideshow) for more details.\n",
      "\n",
      "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
      "\n",
      "    Default: 4\n",
      "\n",
      "    Choices: [1, 2, 3, 4]\n",
      "\n",
      "    The nbformat version to write. Use this to downgrade notebooks.\n",
      "\n",
      "To see all available configurables, use `--help-all`\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "    \n",
      "    > jupyter nbconvert mynotebook.ipynb\n",
      "    \n",
      "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
      "    \n",
      "    You can specify the export format with `--to`.\n",
      "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
      "    \n",
      "    > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "    \n",
      "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
      "    can specify the flavor of the format used.\n",
      "    \n",
      "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
      "    \n",
      "    You can also pipe the output to stdout, rather than a file\n",
      "    \n",
      "    > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "    \n",
      "    PDF is generated via latex\n",
      "    \n",
      "    > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "    \n",
      "    You can get (and serve) a Reveal.js-powered slideshow\n",
      "    \n",
      "    > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "    \n",
      "    Multiple notebooks can be given at the command line in a couple of \n",
      "    different ways:\n",
      "    \n",
      "    > jupyter nbconvert notebook*.ipynb\n",
      "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "    \n",
      "    or you can specify the notebooks list in a config file, containing::\n",
      "    \n",
      "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "    \n",
      "    > jupyter nbconvert --config mycfg.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-learn-env] *",
   "language": "python",
   "name": "conda-env-.conda-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
